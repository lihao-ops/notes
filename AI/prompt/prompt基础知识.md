Prompt基础知识
===



一、什么是Prompt
---

> An Intuitive Definition：

**Prompt** 是一种提供给预训练语言模型的线索，让预训练语言模型能更好地理解人类的问题。

**Prompt（提示）** 是指在计算机程序或用户界面中，用于引导用户输入或行动的一种消息或请求。在自然语言处理（NLP）和机器学习（ML）中，prompt 也指代引导模型生成特定输出的输入文本。



**基本组成部分：**

- **提示文本**：提示用户或系统需要什么类型的输入或操作。
- **响应**：用户或系统对提示的回应。



> 基本应用

在不同的上下文中，prompt 有不同的应用：



**用户界面（UI）提示：**

- **对话框提示**：例如，在应用程序中弹出的对话框，要求用户确认删除操作或输入数据。
- **表单提示**：表单中的字段标签和占位符提示用户输入所需信息，如“请输入您的电子邮件地址”。



**编程中的提示：**

- **命令行提示**：在命令行界面中，提示用户输入命令或参数。例如，Unix shell 的 `$` 提示符。
- **函数提示**：某些编程语言或库中，函数的参数提示用于指导用户正确调用函数。例如，Python 的 `input()` 函数提示用户输入。



**自然语言处理（NLP）中的提示：**

- **生成模型提示**：在像 GPT-4 这样的语言模型中，prompt 是模型生成响应的输入文本。可以是问题、指令或其他形式的输入，模型基于这些提示生成输出。
- **零-shot 和少-shot 学习**：在这种方法中，模型的性能依赖于精心设计的提示来完成特定任务，而无需大量的训练数据。



> More Technical Definition

**Prompt** 是一种在输入中增加额外文本（线索）以更好地利用预训练模型中的知识的技术。如下图所示，BERT 能回答/补全出“JDK 是由 Oracle 研发的”，BART 能对长文本进行总结，ERNIE 能说出鸟类的能力。

在进行 **objective engineering** 的过程中，研究者发现将下游任务的目标与预训练目标对齐会得到更好的效果。因此，下游任务通过引入文本提示符（textual prompt），将原有任务目标重构为与预训练模型一致的填空题。例如：

- **情感预测任务**：
  - 输入：“I missed the bus today. I felt so___.”
  - 其中 “I felt so” 就是提示词（prompt），然后使用语言模型（LM）填入表示情感的词。

- **翻译任务**：
  - 输入：“English: I missed the bus today. French:___.”
  - 其中 “English:” 和 “French:” 就是提示词，然后使用语言模型填入相应的法语句子。

我们发现，使用不同的提示词（prompt）加到相同的输入上，可以实现不同的任务，从而使下游任务更好地对齐到预训练任务上，达到更好的预测效果。后来研究者发现，在同一个任务上使用不同的提示词（prompt），预测效果也会有显著差异，因此现在有许多研究开始聚焦于 **prompt engineering**。





二、Prompt规范格式
---

![image-20240905195340845](https://notes-1307435281.cos.ap-shanghai.myqcloud.com/note/master/202409051953960.png)





三、使用指南
---

### 1.写出清晰指令

任何 **Prompt** 技巧都不如清晰地表达你的需求，这就像人与人沟通一样，如果话说得不明白，怎么能让别人理解你呢？

把大模型当作一个有专业知识和基础逻辑的实习生，像产品经理写需求文档一样书写 Prompt！一味地依靠抄 Prompt 模板可能效果不佳。

1. **需求说详细**  
   尽量多提供任何重要的详细信息和上下文。

   - **案例**：
     - 【反】总结会议记录
     - 【正】用一个段落总结会议记录。然后写下演讲者的 Markdown 列表以及他们的每个要点。最后，列出发言人建议的后续步骤或行动项目（如果有）。

2. **让模型充当某个角色**  
   他会更专业、更明确。

3. **使用分隔符清楚地标识输入的不同部分**  
   比如引号、XML 标签、节标题等。

   - **示例**：
     - 用 50 个字符总结由三引号分隔的文本。
     - ```在此插入文字```。

4. **指定完成任务所需的步骤**  
   最好指定为一系列步骤。明确地写出这些步骤可以使模型更容易实现它们。

   - **示例**：
     - 使用以下分步说明来响应用户输入。
       - 步骤 1 - 用户将为您提供三引号中的文本。用一个句子总结这段文字，并加上前缀「Summary:」。
       - 步骤 2 - 将步骤 1 中的摘要翻译成西班牙语，并添加前缀「翻译：」。

5. **提供例子，少样本提示，few-shot prompt**  
   比如：按这句话的风格来写 XX 文章：

   - **示例**：
     - 落霞与孤鹜齐飞，秋水共长天一色。渔舟唱晚，响穷彭蠡之滨。

6. **指定输出长度**  
   目标输出长度可以根据句子、段落、要点等的计数来指定，但给定的长度只是一个大概。

   - **示例**：
     - 用两个段落、100 个字符概括由三引号分隔的文本。
     - ```在此插入文字```。



### 2.提供参考文本

1. **让大模型使用我们提供的信息来组成其答案**

   比如：
   ```markdown
   使用提供的由三重引号引起来的文章来回答问题。如果在文章中找不到答案，请写「我找不到答案」。
   """
   <在此插入文档>
   """
   问题：<在此插入问题>
   ```

2. **让模型通过引用提供的参考文本来回答**

   比如：
   ```markdown
   您将获得一份由三重引号和一个问题分隔的文档。您的任务是仅使用提供的文档回答问题，并引用用于回答问题的文档段落。如果文档不包含回答此问题所需的信息，则只需写：「信息不足」。如果提供了问题的答案，则必须附有引文注释。
   使用以下格式引用相关段落（{「引用」：…}）。
   """
   <在此插入文档>
   """
   问题：<在此插入问题>
   ```

---

这将帮助确保大模型能够准确使用和引用提供的参考文本。



### 3.分解复杂任务

将复杂的任务拆分为更简单的子任务，有助于提高大模型的表现。这种方法类似于在项目管理中将大型项目拆分为多个子任务，以降低出错的概率。

1. **使用意图分类来识别与用户查询最相关的指令**

   - 首先识别用户的意图，然后根据意图提供对应的参考信息和更详细的指令，以解决最终问题。

   - **示例**：
     ```markdown
     用户查询意图分类为“寻找产品信息”。根据这一意图，提供以下参考信息和指令：
     - 参考信息：产品规格、价格、购买链接。
     - 指令：提供产品的详细规格、当前价格以及购买链接。
     ```

2. **对于需要很长对话的对话应用，总结或过滤之前的对话**

   模型具有固定的上下文长度，因此用户和助手之间的对话无法无限期地继续。可以采用以下方法解决此问题：

   - **总结对话中的历史记录**：
     一旦输入的大小达到预定的阈值长度，这可能会触发总结部分对话的查询。先前对话的摘要可以作为系统消息的一部分包括在内。

     - **示例**：
       ```markdown
       对话记录摘要：用户询问了产品的功能、价格和购买链接，系统提供了相关信息。接下来，用户询问了关于退货政策的问题。
       ```

   - **在整个对话过程中在后台异步总结之前的对话**：
     在对话进行过程中，后台可以异步总结之前的对话内容，以便在需要时使用。

   - **把过去的所有聊天记录存成向量库**：
     将聊天记录存储为向量，并在后续对话中动态查询这些嵌入，以保持对话的一致性和上下文相关性。

     - **示例**：
       ```markdown
       存储历史对话记录的向量库：
       - 对话 1：用户询问产品规格
       - 对话 2：用户询问价格
       - 对话 3：用户询问购买链接
       ```

---

这种方法可以有效提高大模型处理复杂任务的能力，确保模型能够更好地理解和响应用户的需求。



### 4.给模型思考时间

**Think Step by Step (COT)**

1. **让模型在急于得出结论之前找出自己的解决方案**

   - 先让大模型输出一个解决方案，然后让模型点评和判断它的方案是否正确。最终，让模型结合判断解释得到最终方案。

   - **示例**：
     ```markdown
     问题陈述：<在此插入问题>
     模型解决方案：<在此插入模型的初步方案>
     模型点评：<在此插入模型对其方案的评价>
     最终方案：<在此插入经过点评和判断后的最终方案>
     ```

2. **使用内心独白**

   - 让模型将原本对用户隐藏的部分输出放入结构化格式中，以便于解析。然后，在向用户呈现输出之前，解析输出并仅显示部分输出。

   - **示例**：
     ```markdown
     问题陈述：<在此插入问题>
     您的解决方案：<在此插入模型的解决方案>
     学生解决方案：<在此插入学生的解决方案>
     分析：<在此插入对解决方案的分析>
     ```
     - 找出解决方案；将解决方案与学生的方案进行比较；如果学生犯错，提供提示而不泄露答案；如果学生犯错，提供上一步的提示。

3. **询问模型在之前的过程中是否遗漏了什么内容**

   - 在长文本问答中常用。比如，给模型一个文档，让它列出与特定问题相关的信息。如果源文档很大，模型可能会过早停止并且无法列出所有相关信息。使用后续的 Prompt 让模型查找之前传递中遗漏的任何相关信息，通常可以获得更好的性能。

   - **示例**：
     ```markdown
     问题：北京烤鸭到底好吃在哪？
     根据文档列出相关片段：<在此插入初步结果>
     ```
     - 在输出停止后，再问一句：
       ```markdown
       还有更多相关片段吗？注意不要重复摘录。确保相关片段包含解释它们所需的所有相关上下文 - 换句话说，不要提取缺少重要上下文的小片段。
       ```

---

这些方法有助于提高模型在处理复杂任务时的准确性和有效性。





四、使用外部工具
---

![image-20240905195920927](https://notes-1307435281.cos.ap-shanghai.myqcloud.com/note/master/202409051959068.png)



![image-20240905195930253](https://notes-1307435281.cos.ap-shanghai.myqcloud.com/note/master/202409051959337.png)





五、系统测试变更
---

能够帮助开发者判断更改Prompt是否使系统变得更好或更差

> 每个Prompt更改都要做测试！！！